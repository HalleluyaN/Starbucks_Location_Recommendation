{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-IbGQudnhVv"
   },
   "source": [
    "## Fetch brand locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TbgGJI2jngRM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                     | 104/1534 [00:56<13:02,  1.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m local_poi_data\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 82\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(executor\u001b[38;5;241m.\u001b[39mmap(scrape_location, grid_points), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(grid_points)))\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     85\u001b[0m     poi_data\u001b[38;5;241m.\u001b[39mextend(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "API_KEY = \"AIzaSyC1y0zKO0nnY6OOlUMs5ciN2EKygF8xAuM\"\n",
    "\n",
    "NEARBY_SEARCH_URL = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "# List of Brands\n",
    "brands = [\"Starbucks\", \"McDonald's\", \"Walmart\", \"Target\"]\n",
    "\n",
    "# USA Boundaries\n",
    "USA_BOUNDS = {\n",
    "    \"lat_min\": 24.5, \"lat_max\": 49.5,\n",
    "    \"lon_min\": -125.0, \"lon_max\": -66.9\n",
    "}\n",
    "\n",
    "LAT_STEP = 1.0\n",
    "LON_STEP = 1.0\n",
    "SEARCH_RADIUS = 75000\n",
    "\n",
    "def get_pois(brand, lat, lon):\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": SEARCH_RADIUS,\n",
    "        \"keyword\": brand,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(NEARBY_SEARCH_URL, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"results\" in data:\n",
    "            for place in data[\"results\"]:\n",
    "                all_results.append({\n",
    "                    \"brand\": brand,\n",
    "                    \"name\": place.get(\"name\"),\n",
    "                    \"latitude\": place[\"geometry\"][\"location\"][\"lat\"],\n",
    "                    \"longitude\": place[\"geometry\"][\"location\"][\"lng\"],\n",
    "                    \"address\": place.get(\"vicinity\", \"N/A\"),\n",
    "                    \"place_id\": place.get(\"place_id\"),\n",
    "                    \"rating\": place.get(\"rating\", \"N/A\"),\n",
    "                    \"user_ratings_total\": place.get(\"user_ratings_total\", \"N/A\")\n",
    "                })\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        params[\"pagetoken\"] = next_page_token\n",
    "        time.sleep(2)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def generate_grid(lat_min, lat_max, lon_min, lon_max):\n",
    "    grid_points = []\n",
    "    lat = lat_min\n",
    "    while lat <= lat_max:\n",
    "        lon = lon_min\n",
    "        while lon <= lon_max:\n",
    "            grid_points.append((lat, lon))\n",
    "            lon += LON_STEP\n",
    "        lat += LAT_STEP\n",
    "    return grid_points\n",
    "\n",
    "poi_data = []\n",
    "grid_points = generate_grid(USA_BOUNDS[\"lat_min\"], USA_BOUNDS[\"lat_max\"], USA_BOUNDS[\"lon_min\"], USA_BOUNDS[\"lon_max\"])\n",
    "\n",
    "def scrape_location(lat_lon):\n",
    "    lat, lon = lat_lon\n",
    "    local_poi_data = []\n",
    "    for brand in brands:\n",
    "        local_poi_data.extend(get_pois(brand, lat, lon))\n",
    "    return local_poi_data\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(tqdm(executor.map(scrape_location, grid_points), total=len(grid_points)))\n",
    "\n",
    "for result in results:\n",
    "    poi_data.extend(result)\n",
    "\n",
    "df = pd.DataFrame(poi_data).drop_duplicates(subset=[\"place_id\"])\n",
    "\n",
    "# df.to_csv(\"data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAKBvk0Ynj0l"
   },
   "source": [
    "## Fetch restaurants and cafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xz4vdEQ7zaaN"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "API_KEY = \"AIzaSyB22-hL86l-7Adt3Hf93k932Z_PnWhtBWQ\"\n",
    "\n",
    "NEARBY_SEARCH_URL = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "USA_BOUNDS = {\n",
    "    \"lat_min\": 24.5, \"lat_max\": 49.5,  # Continental USA latitude range\n",
    "    \"lon_min\": -125.0, \"lon_max\": -66.9  # Continental USA longitude range\n",
    "}\n",
    "\n",
    "LAT_STEP = 0.5\n",
    "LON_STEP = 0.5\n",
    "SEARCH_RADIUS = 75000  # Increased from 50 km to 75 km to cover more area\n",
    "\n",
    "# Function to get restaurants in a specific lat/lon area\n",
    "def get_restaurants(lat, lon):\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": SEARCH_RADIUS,\n",
    "        \"type\": \"coffee\",  # Search for restaurants\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(NEARBY_SEARCH_URL, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if \"results\" in data:\n",
    "            for place in data[\"results\"]:\n",
    "                all_results.append({\n",
    "                    \"name\": place.get(\"name\"),\n",
    "                    \"latitude\": place[\"geometry\"][\"location\"][\"lat\"],\n",
    "                    \"longitude\": place[\"geometry\"][\"location\"][\"lng\"],\n",
    "                    \"address\": place.get(\"vicinity\", \"N/A\"),\n",
    "                    \"place_id\": place.get(\"place_id\"),\n",
    "                    \"rating\": place.get(\"rating\", \"N/A\"),\n",
    "                    \"user_ratings_total\": place.get(\"user_ratings_total\", \"N/A\")\n",
    "                })\n",
    "\n",
    "        next_page_token = data.get(\"next_page_token\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        params[\"pagetoken\"] = next_page_token\n",
    "        time.sleep(2)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def generate_grid(lat_min, lat_max, lon_min, lon_max):\n",
    "    grid_points = []\n",
    "    lat = lat_min\n",
    "    while lat <= lat_max:\n",
    "        lon = lon_min\n",
    "        while lon <= lon_max:\n",
    "            grid_points.append((lat, lon))\n",
    "            lon += LON_STEP\n",
    "        lat += LAT_STEP\n",
    "    return grid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_j-CjrRzfkz",
    "outputId": "0a636563-2323-4430-d002-3a25b32315d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5967/5967 [1:07:08<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fetch restaurants for all locations in the USA\n",
    "poi_data = []\n",
    "grid_points = generate_grid(USA_BOUNDS[\"lat_min\"], USA_BOUNDS[\"lat_max\"], USA_BOUNDS[\"lon_min\"], USA_BOUNDS[\"lon_max\"])\n",
    "\n",
    "def scrape_location(lat_lon):\n",
    "    lat, lon = lat_lon\n",
    "    return get_restaurants(lat, lon)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(tqdm(executor.map(scrape_location, grid_points), total=len(grid_points)))\n",
    "\n",
    "for result in results:\n",
    "    poi_data.extend(result)\n",
    "\n",
    "df = pd.DataFrame(poi_data).drop_duplicates(subset=[\"place_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8snaLGiG0dgV",
    "outputId": "35f3f8f0-901a-4fa5-c172-a97ad9995371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165157, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jsW4vfCm0z5s"
   },
   "outputs": [],
   "source": [
    "df.to_csv('coffee.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
